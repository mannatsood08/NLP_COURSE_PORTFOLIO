<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Unit 4 - Language Models | NLP Portfolio</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <!-- Custom Cursor -->
    <div class="cursor"></div>
    
    <!-- Progress Bar -->
    <div class="progress-container">
        <div class="progress-bar"></div>
    </div>
    
    <!-- Header & Navigation -->
    <header>
        <div class="container">
            <nav class="navbar">
                <a href="index.html" class="logo">NLP Portfolio</a>
                
                <ul class="nav-menu">
                    <li class="nav-item">
                        <a href="index.html" class="nav-link">Home</a>
                    </li>
                    <li class="nav-item">
                        <a href="about.html" class="nav-link">About the Course</a>
                    </li>
                    <li class="nav-item">
                        <a href="objectives.html" class="nav-link">Learning Objectives</a>
                    </li>
                    <li class="nav-item dropdown">
                        <a href="#" class="nav-link active">Units</a>
                        <div class="dropdown-content">
                            <a href="unit1.html">Unit 1</a>
                            <a href="unit2.html">Unit 2</a>
                            <a href="unit3.html">Unit 3</a>
                            <a href="unit4.html">Unit 4</a>
                            <a href="unit5.html">Unit 5</a>
                        </div>
                    </li>
                    <li class="nav-item">
                        <a href="reflection.html" class="nav-link">Reflection</a>
                    </li>
                    <li class="nav-item">
                        <a href="achievements.html" class="nav-link">Achievements</a>
                    </li>
                </ul>
                
                <div class="hamburger">
                    <span class="bar"></span>
                    <span class="bar"></span>
                    <span class="bar"></span>
                </div>
            </nav>
        </div>
    </header>
    
    <!-- Unit Content -->
    <section>
        <div class="container">
            <div class="unit-header fade-in">
                <div class="unit-icon">
                    <svg width="80" height="80" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                        <path d="M3 17.25V21H6.75L17.81 9.94L14.06 6.19L3 17.25ZM20.71 7.04C21.1 6.65 21.1 6.02 20.71 5.63L18.37 3.29C17.98 2.9 17.35 2.9 16.96 3.29L15.13 5.12L18.88 8.87L20.71 7.04Z" fill="#00f3ff"/>
                    </svg>
                </div>
                <h1>Unit 4 — Language Models</h1>
                <p>Duration: 9 Hours</p>
            </div>
            
            <div class="unit-content fade-in">
                <p>This unit explores advanced neural architectures for language understanding, focusing on sequence modeling and transformer-based approaches that have revolutionized natural language processing.</p>
                
                <h2>Topics Covered</h2>
                <ul class="unit-topics">
                    <li>Recurrent Neural Networks (RNNs): Architecture and applications</li>
                    <li>Long Short-Term Memory (LSTM): Addressing vanishing gradients</li>
                    <li>Gated Recurrent Units (GRUs): Efficient sequence modeling</li>
                    <li>Attention mechanisms: Understanding context dependencies</li>
                    <li>Transformer architecture: Self-attention and positional encoding</li>
                    <li>BERT: Bidirectional Encoder Representations from Transformers</li>
                    <li>GPT models: Generative Pre-trained Transformers</li>
                    <li>Fine-tuning pre-trained models for specific tasks</li>
                    <li>Transfer learning in NLP</li>
                </ul>
                
                <h2>Key Takeaways</h2>
                <p>This unit provided comprehensive understanding of neural language models, from basic RNNs to state-of-the-art transformer architectures. The focus on pre-trained models and fine-tuning techniques demonstrated practical approaches to leveraging large-scale language understanding for specific applications.</p>
                
                <a href="objectives.html" class="back-link">← Back to Learning Objectives</a>
            </div>
        </div>
    </section>
    
    <!-- Back to Top Button -->
    <div class="back-to-top">
        <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
            <path d="M7.41 15.41L12 10.83L16.59 15.41L18 14L12 8L6 14L7.41 15.41Z" fill="currentColor"/>
        </svg>
    </div>
    
    <!-- Footer -->
    <footer>
        <div class="footer-content">
            <p>© Mannat Sood | NLP Course Portfolio</p>
        </div>
    </footer>
    
    <script src="script.js"></script>
</body>
</html>

